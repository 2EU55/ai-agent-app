import os
import ast
import re
import operator
from typing import Annotated, Sequence, TypedDict, Union, List, Literal

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_experimental.tools.python.tool import PythonAstREPLTool
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_not_exception_type

# å¼•å…¥æˆ‘ä»¬åˆšæ‰åˆ›å»ºçš„ config å’Œ logger
from config import Config, logger
from rag_tool import search_company_policy

class LLMAuthError(Exception):
    pass

# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„ LLM è°ƒç”¨è£…é¥°å™¨
# retry: é‡è¯•è£…é¥°å™¨
# stop_after_attempt(3): æœ€å¤šé‡è¯• 3 æ¬¡
# wait_exponential(multiplier=1, min=2, max=10): æŒ‡æ•°é€€é¿ç­–ç•¥ï¼Œç¬¬ä¸€æ¬¡ç­‰ 2sï¼Œç¬¬äºŒæ¬¡ç­‰ 4sï¼Œç¬¬ä¸‰æ¬¡ç­‰ 8s...
# retry_if_exception_type(Exception): é‡åˆ°ä»»ä½•å¼‚å¸¸éƒ½é‡è¯• (ç”Ÿäº§ç¯å¢ƒå»ºè®®åªæ•è·ç½‘ç»œç›¸å…³çš„å¼‚å¸¸)
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_not_exception_type(LLMAuthError),
    reraise=True,
)
async def safe_ainvoke_llm(chain_or_llm, input_data):
    """
    å¼‚æ­¥å®‰å…¨è°ƒç”¨ LLMï¼Œå¸¦æœ‰è‡ªåŠ¨é‡è¯•æœºåˆ¶ã€‚
    """
    try:
        # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ ainvoke (Async Invoke)
        response = await chain_or_llm.ainvoke(input_data)
        
        # å…¼å®¹æ—§ç‰ˆ ChatOpenAI (function_call)
        if hasattr(response, "additional_kwargs") and "function_call" in response.additional_kwargs:
            if not getattr(response, "tool_calls", None):
                import json
                fc = response.additional_kwargs["function_call"]
                response.tool_calls = [{
                    "name": fc["name"],
                    "args": json.loads(fc["arguments"]),
                    "id": "call_" + fc["name"],
                    "type": "tool_call"
                }]
        return response
    except Exception as e:
        msg = str(e)
        if ("401" in msg) and ("api key" in msg.lower() or "invalid" in msg.lower()):
            logger.error(f"LLM é‰´æƒå¤±è´¥ï¼š{msg}")
            raise LLMAuthError(msg) from e
        logger.warning(f"LLM å¼‚æ­¥è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... é”™è¯¯: {msg}")
        raise e

# 1. å®šä¹‰çŠ¶æ€ (State)
class AgentState(TypedDict, total=False):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    next: str
    pending_analyst_code: str | None
    route: str
    route_method: str

# 2. å®šä¹‰ Router (è·¯ç”±å™¨)
# èŒè´£ï¼šåˆ†æç”¨æˆ·æ„å›¾ï¼Œå†³å®šä¸‹ä¸€æ­¥å»å“ª
class RouterOutput(BaseModel):
    """Router output model"""
    next: Literal["analyst", "expert", "general"] = Field(
        ..., 
        description="The next node to route to. 'analyst' for data analysis, 'expert' for policy questions, 'general' for other queries."
    )

def _is_confirm_text(text: str) -> bool:
    t = (text or "").strip().lower()
    if not t:
        return False
    patterns = [
        r"^(ç¡®è®¤|ç¡®è®¤æ‰§è¡Œ|æ‰§è¡Œ|ç»§ç»­|è¿è¡Œ|å¼€å§‹|å¥½|å¥½çš„|å¯ä»¥|ok|okay|yes|y)$",
        r"ç¡®è®¤ä¸€ä¸‹",
        r"ç¡®è®¤å¹¶æ‰§è¡Œ",
        r"æ‰§è¡Œå§",
        r"ç»§ç»­å§",
    ]
    return any(re.search(p, t) for p in patterns)


def _is_cancel_text(text: str) -> bool:
    t = (text or "").strip().lower()
    if not t:
        return False
    patterns = [
        r"^(å–æ¶ˆ|ä¸æ‰§è¡Œ|åœæ­¢|ç®—äº†|æ’¤é”€|no|n)$",
        r"å…ˆä¸æ‰§è¡Œ",
        r"ä¸è¦æ‰§è¡Œ",
    ]
    return any(re.search(p, t) for p in patterns)


def _extract_python_code(text: str) -> str:
    s = (text or "").strip()
    if not s:
        return ""
    m = re.search(r"```(?:python)?\s*([\s\S]*?)```", s, flags=re.IGNORECASE)
    if m:
        return (m.group(1) or "").strip()
    return s


def _sanitize_generated_code(code: str) -> str:
    s = (code or "").strip()
    if not s:
        return ""
    s = re.sub(r"(?m)^(?:from\s+\S+\s+import\s+.*|import\s+.*)\s*$", "", s)
    s = re.sub(r"(?ms)^def\s+save_figure\s*\(\s*\)\s*:\s*\n(?:[ \t].*\n)+", "", s)
    s = re.sub(r"(?m)^\s*plt\.show\s*\(.*\)\s*$", "", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def _fallback_analyst_code(question: str, need_plot: bool) -> str:
    q = (question or "").strip()
    if not q:
        return ""

    is_sales = any(k in q for k in ("é”€å”®", "é”€å”®é¢", "sales"))
    is_profit = any(k in q for k in ("åˆ©æ¶¦", "profit"))

    metric_col = "sales" if is_sales or not is_profit else "profit"
    metric_cn = "é”€å”®é¢" if metric_col == "sales" else "åˆ©æ¶¦"
    want_only_number = "åªè¾“å‡ºä¸€ä¸ªæ•°å­—" in q or "åªè¾“å‡ºä¸€ä¸ªæ•°" in q or "åªè¾“å‡ºæ•°å­—" in q

    if any(k in q for k in ("æŒ‰äº§å“", "æ±‡æ€»")) and any(k in q.lower() for k in ("top3", "top 3", "top-3", "top")):
        return "\n".join(
            [
                f"metric_col = '{metric_col}'",
                f"metric_cn = '{metric_cn}'",
                "tmp = df.dropna(subset=['product'])",
                "agg = tmp.groupby('product')[metric_col].sum().sort_values(ascending=False).head(3)",
                "for name, value in agg.items():",
                "    print(f\"{name}: {float(value):g}\")",
            ]
        )

    if any(k in q for k in ("æŒ‰äº§å“", "æ±‡æ€»", "top3", "TOP3")):
        return "\n".join(
            [
                f"metric_col = '{metric_col}'",
                f"metric_cn = '{metric_cn}'",
                "tmp = df.dropna(subset=['product'])",
                "agg = tmp.groupby('product')[metric_col].sum().sort_values(ascending=False).head(3)",
                "for name, value in agg.items():",
                "    print(f\"{name}: {float(value):g}\")",
            ]
        )

    if need_plot:
        return "\n".join(
            [
                f"metric_col = '{metric_col}'",
                f"metric_cn = '{metric_cn}'",
                "tmp = df.dropna(subset=['date'])",
                "series = tmp.groupby('date')[metric_col].sum().sort_index()",
                "plt.figure(figsize=(10, 6))",
                "series.plot(kind='line', marker='o')",
                "plt.title(f'{metric_cn}è¶‹åŠ¿')",
                "plt.xlabel('æ—¥æœŸ')",
                "plt.ylabel(metric_cn)",
                "plt.xticks(rotation=45)",
                "plt.grid(True)",
                "save_figure()",
                "print(\"å›¾è¡¨å·²ç”Ÿæˆ\")",
            ]
        )

    if "ä¸­ä½æ•°" in q or "median" in q.lower():
        return "\n".join(
            [
                f"metric_col = '{metric_col}'",
                "tmp = df.dropna(subset=[metric_col])",
                "v = float(tmp[metric_col].median())",
                "print(f\"{v:g}\" if "
                + ("True" if want_only_number else "False")
                + " else f\"{v:g}\")",
            ]
        )

    if "æœ€é«˜" in q or "æœ€å¤§" in q or "top" in q.lower():
        return "\n".join(
            [
                f"metric_col = '{metric_col}'",
                f"metric_cn = '{metric_cn}'",
                "tmp = df.dropna(subset=['date'])",
                "daily = tmp.groupby('date')[metric_col].sum()",
                "best_date = daily.idxmax()",
                "best_value = float(daily.max())",
                "best_date_str = best_date.date().isoformat() if hasattr(best_date, 'date') else str(best_date)",
                "print(f\"{metric_cn}æœ€é«˜çš„æ—¥æœŸæ˜¯ {best_date_str}ï¼Œ{metric_cn}ä¸º {best_value:g}\")",
            ]
        )

    return "\n".join(
        [
            f"metric_col = '{metric_col}'",
            f"metric_cn = '{metric_cn}'",
            "tmp = df.dropna(subset=['date'])",
            "total = float(tmp[metric_col].sum())",
            "print(f\"{total:g}\" if "
            + ("True" if want_only_number else "False")
            + " else f\"æ€»{metric_cn}ä¸º {total:g}\")",
        ]
    )


def _fallback_policy_search(query: str, policy_path: str) -> str:
    q = (query or "").strip()
    if not q:
        return "è¯·æä¾›è¦æŸ¥è¯¢çš„æ”¿ç­–é—®é¢˜ã€‚"
    if not os.path.exists(policy_path):
        return "é”™è¯¯ï¼šæ‰¾ä¸åˆ° company_policy.txtï¼Œæ— æ³•è¿›è¡Œæ”¿ç­–æ£€ç´¢ã€‚"

    text = ""
    try:
        with open(policy_path, "r", encoding="utf-8") as f:
            text = f.read()
    except Exception:
        try:
            with open(policy_path, "r", encoding="gbk") as f:
                text = f.read()
        except Exception:
            return "è¯»å–æ”¿ç­–æ–‡ä»¶å¤±è´¥ã€‚"

    blocks = [b.strip() for b in re.split(r"\n(?=##\s)", text) if b.strip()]
    raw_tokens = [t for t in re.split(r"\s+", re.sub(r"[^\u4e00-\u9fa5A-Za-z0-9]+", " ", q)) if t]
    stop = {"å…¬å¸", "ä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "æ˜¯å¦", "å¤šå°‘", "è§„å®š", "æ ‡å‡†", "éœ€è¦", "é‡åˆ°", "æ€ä¹ˆåŠ", "å®šä¹‰"}
    tokens: list[str] = []
    for t in raw_tokens:
        if t in stop:
            continue
        if re.fullmatch(r"[A-Za-z0-9]+", t):
            tokens.append(t.lower())
            continue
        if re.search(r"[\u4e00-\u9fa5]", t):
            if len(t) <= 4:
                tokens.append(t)
            else:
                for n in (2, 3, 4):
                    for i in range(0, len(t) - n + 1):
                        tokens.append(t[i : i + n])
    keywords = [
        "å‡ºå·®",
        "å·®æ—…",
        "æŠ¥é”€",
        "ä½å®¿",
        "äº¤é€š",
        "é¤é¥®",
        "è¡¥è´´",
        "å¹´å‡",
        "ç—…å‡",
        "å‘è–ªæ—¥",
        "è–ªé…¬",
        "ç»©æ•ˆ",
        "åˆ©æ¶¦ç‡",
        "æ ‡å‡†åˆ©æ¶¦ç‡",
        "AIè¯¾ç¨‹",
    ]
    for k in keywords:
        if k in q and k not in tokens:
            tokens.append(k)
    tokens = list(dict.fromkeys([t for t in tokens if t and t not in stop]))
    if not tokens:
        tokens = [q]

    if re.search(r"\b[aA]\s*/\s*[bB]\s*/\s*[cC]\b", q) or "A/B/C" in q or "a/b/c" in q:
        if not re.search(r"\b[aA]\s*/\s*[bB]\s*/\s*[cC]\b", text) and "A/B/C" not in text and "a/b/c" not in text:
            return "æœªæ‰¾åˆ°ç›¸å…³æ”¿ç­–å†…å®¹ã€‚"

    def score_block(b: str) -> int:
        s = 0
        for t in tokens:
            if t and t in b:
                s += 2
        if any(k in q for k in ("æŠ¥é”€", "å·®æ—…", "å‡ºå·®")) and "å·®æ—…" in b:
            s += 3
        return s

    ranked = sorted(((score_block(b), b) for b in blocks), key=lambda x: x[0], reverse=True)
    top = [b for s, b in ranked if s > 0][:2]
    if not top:
        return "æœªæ‰¾åˆ°ç›¸å…³æ”¿ç­–å†…å®¹ã€‚"

    out = []
    for i, b in enumerate(top, 1):
        out.append(f"[ç‰‡æ®µ{i}]\n{b}")
    return "\n\n".join(out).strip()


def _looks_dangerous(code: str) -> bool:
    return bool(detect_dangerous_patterns(code))


def detect_dangerous_patterns(code: str) -> list[str]:
    s = (code or "").lower()
    banned = [
        "subprocess",
        "socket",
        "requests",
        "httpx",
        "urllib",
        "websocket",
        "shutil.rmtree",
        "os.remove",
        "os.rmdir",
        "os.system",
        "pathlib.path(",
        "open(",
        "exec(",
        "eval(",
        "__import__(",
        "pip install",
    ]
    hits: list[str] = []
    for x in banned:
        if x in s:
            hits.append(f"string:{x}")

    hits.extend(_detect_ast_risks(code))
    return list(dict.fromkeys(hits))


def build_risk_report(code: str) -> dict:
    matched = detect_dangerous_patterns(code)
    danger = bool(matched)
    block_code = "dangerous_code"
    if any(str(x).startswith("ast:") for x in matched):
        block_code = "ast_disallowed"
    return {"dangerous": danger, "matched": matched, "code": block_code}


def _detect_ast_risks(code: str) -> list[str]:
    src = (code or "").strip()
    if not src:
        return []
    try:
        tree = ast.parse(src)
    except Exception as e:
        return [f"ast:parse_error:{type(e).__name__}"]

    disallowed_nodes = (
        ast.Import,
        ast.ImportFrom,
        ast.With,
        ast.AsyncWith,
        ast.Try,
        ast.Raise,
        ast.Lambda,
        ast.FunctionDef,
        ast.AsyncFunctionDef,
        ast.ClassDef,
        ast.Delete,
        ast.While,
        ast.AsyncFor,
        ast.Await,
        ast.Yield,
        ast.YieldFrom,
        ast.Global,
        ast.Nonlocal,
    )

    blocked_root_names = {"os", "sys", "subprocess", "socket", "shutil", "pathlib"}
    blocked_call_names = {"open", "exec", "eval", "compile", "__import__", "input"}

    def dotted_name(n) -> str:
        parts: list[str] = []
        cur = n
        while isinstance(cur, ast.Attribute):
            parts.append(cur.attr)
            cur = cur.value
        if isinstance(cur, ast.Name):
            parts.append(cur.id)
        parts.reverse()
        return ".".join(parts)

    hits: list[str] = []
    for n in ast.walk(tree):
        if isinstance(n, disallowed_nodes):
            hits.append(f"ast:node:{type(n).__name__}")
            continue

        if isinstance(n, ast.Name) and n.id in blocked_root_names:
            hits.append(f"ast:name:{n.id}")

        if isinstance(n, ast.Attribute) and (n.attr or "").startswith("__"):
            hits.append("ast:dunder_attr")

        if isinstance(n, ast.Call):
            fn = n.func
            if isinstance(fn, ast.Name) and fn.id in blocked_call_names:
                hits.append(f"ast:call:{fn.id}")
                continue
            if isinstance(fn, ast.Attribute):
                dn = dotted_name(fn)
                root = dn.split(".", 1)[0] if dn else ""
                if root in blocked_root_names:
                    hits.append(f"ast:call:{dn}")
                    continue
                if any(p.startswith("__") for p in dn.split(".")):
                    hits.append("ast:call:dunder")

        if isinstance(n, ast.Constant) and isinstance(n.value, str):
            v = n.value.lower()
            if "pip install" in v:
                hits.append("ast:string:pip install")

    return list(dict.fromkeys(hits))


async def router_node(state: AgentState):
    logger.info("ğŸš¦ è¿›å…¥ Router èŠ‚ç‚¹...")
    messages = state["messages"]
    last_user_text = ""
    for m in reversed(list(messages)):
        if isinstance(m, HumanMessage):
            last_user_text = (m.content or "").strip()
            break

    q = last_user_text.lower()
    pending_code = state.get("pending_analyst_code")
    if pending_code:
        logger.info("ğŸ‘‰ Router æ£€æµ‹åˆ°å¾…ç¡®è®¤çš„ Analyst ä»£ç ï¼Œä¼˜å…ˆè·¯ç”±åˆ° analyst")
        return {"next": "analyst", "route": "analyst", "route_method": "pending_code"}
    if q:
        # 1. General è§„åˆ™
        general_patterns = [
            r"\bhi\b",
            r"\bhello\b",
            r"\bhey\b",
            r"ä½ å¥½",
            r"åœ¨å—",
            r"ä½ æ˜¯è°",
            r"ä½ èƒ½åšä»€ä¹ˆ",
            r"ä½ å¯ä»¥åšä»€ä¹ˆ",
            r"ä½ ä¼šä»€ä¹ˆ",
            r"ä»‹ç»ä¸€ä¸‹ä½ ",
            r"è‡ªæˆ‘ä»‹ç»",
            r"æ€ä¹ˆç”¨",
            r"ä½¿ç”¨è¯´æ˜",
            r"help",
            r"capabilit",
            r"what can you do",
            r"who are you",
        ]
        if any(re.search(p, q) for p in general_patterns):
            logger.info("ğŸ‘‰ Router è§„åˆ™å‘½ä¸­ï¼šè·¯ç”±åˆ° general")
            return {"next": "general", "route": "general", "route_method": "rule"}
        
        # 2. Expert è§„åˆ™ (æ”¿ç­–å¼ºç‰¹å¾)
        expert_patterns = [
            # æ ¸å¿ƒå®ä½“
            r"æŠ¥é”€", r"å‘ç¥¨", r"å·®æ—…", r"å‡ºå·®", r"ä½å®¿", r"æœºç¥¨", r"é£æœº", r"ç«è½¦", r"äº¤é€š", r"é¤é¥®", r"è¡¥è´´",
            r"å¹´å‡", r"ç—…å‡", r"äº‹å‡", r"å©šå‡", r"äº§å‡", r"è€ƒå‹¤", r"æ‰“å¡", r"è¿Ÿåˆ°", r"æ—©é€€", 
            r"åŠ ç­", r"è°ƒä¼‘", r"è–ªèµ„", r"å·¥èµ„", r"å‘è–ª", r"å¥–é‡‘", r"ç»©æ•ˆ", r"æ™‹å‡", r"ç¦åˆ©", r"ç¤¾ä¿", r"å…¬ç§¯é‡‘",
            r"åˆ©æ¶¦ç‡", r"æ ‡å‡†åˆ©æ¶¦",
            # æ–‡æ¡£ç±»å‹
            r"æ”¿ç­–", r"è§„å®š", r"åˆ¶åº¦", r"æ‰‹å†Œ", r"æµç¨‹", r"æ ‡å‡†",
        ]
        if any(re.search(p, q) for p in expert_patterns):
             logger.info("ğŸ‘‰ Router è§„åˆ™å‘½ä¸­ï¼šè·¯ç”±åˆ° expert")
             return {"next": "expert", "route": "expert", "route_method": "rule"}

        # 3. Analyst è§„åˆ™ (æ•°æ®åˆ†æå¼ºç‰¹å¾)
        analyst_patterns = [
            # æ˜ç¡®çš„åŠ¨ä½œ
            r"(ç”»|ç»˜|ç”Ÿæˆ|å±•ç¤º).*(å›¾|è¡¨|æ›²çº¿|åˆ†å¸ƒ|è¶‹åŠ¿)",
            r"(ç»Ÿè®¡|åˆ†æ|è®¡ç®—|æ±‡æ€»|æ±‚).*(æ•°æ®|é”€å”®|åˆ©æ¶¦|æˆæœ¬)",
            # æ˜ç¡®çš„åˆ—å/æŒ‡æ ‡
            r"é”€å”®é¢", r"åˆ©æ¶¦", r"æˆæœ¬", r"å®¢å•ä»·", r"å¢é•¿ç‡",
            r"å¤šå°‘é’±", r"é‡‘é¢", r"æ€»å’Œ", r"æ€»è®¡",
            r"æ’å", r"æ’è¡Œ", r"top", r"å‰\d+",
            r"ä¸­ä½æ•°", r"å¹³å‡", r"æœ€é«˜", r"æœ€ä½",
            r"å“ªå¤©", r"å‡ å·", r"å‡ æœˆ",
        ]
        if any(re.search(p, q) for p in analyst_patterns):
             logger.info("ğŸ‘‰ Router è§„åˆ™å‘½ä¸­ï¼šè·¯ç”±åˆ° analyst")
             return {"next": "analyst", "route": "analyst", "route_method": "rule"}

    
    # å®šä¹‰ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è·¯ç”±åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ï¼Œå†³å®šå°†è¯·æ±‚è½¬å‘ç»™å“ªä¸ªä¸“å®¶ã€‚
    
    - å¦‚æœç”¨æˆ·çš„é—®é¢˜æ¶‰åŠåˆ°æ•°æ®åˆ†æã€å›¾è¡¨ç»˜åˆ¶ã€ç»Ÿè®¡è®¡ç®—ï¼ˆå¦‚é”€å”®é¢ã€å¢é•¿ç‡ç­‰ï¼‰ï¼Œè¯·è½¬å‘ç»™ "analyst"ã€‚
    - å¦‚æœç”¨æˆ·çš„é—®é¢˜æ¶‰åŠåˆ°å…¬å¸æ”¿ç­–ã€è§„ç« åˆ¶åº¦ã€æŠ¥é”€æµç¨‹ã€æ”¾å‡å®‰æ’ç­‰ï¼Œè¯·è½¬å‘ç»™ "expert"ã€‚
    - å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯é—²èŠã€è‡ªæˆ‘ä»‹ç»ã€èƒ½åŠ›ä»‹ç»ã€æˆ–æ˜æ˜¾ä¸å±äºä»¥ä¸Šä¸¤ç±»ï¼Œè¯·è½¬å‘ç»™ "general"ã€‚
    - å¦‚æœåœ¨ "analyst" ä¸ "expert" ä¹‹é—´ä¸ç¡®å®šï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼Œä¼˜å…ˆè€ƒè™‘ "expert"ã€‚
    """
    
    if not Config.SILICONFLOW_API_KEY:
        logger.info("ğŸ‘‰ æœªé…ç½® SILICONFLOW_API_KEYï¼ŒRouter é»˜è®¤è·¯ç”±åˆ° general")
        return {"next": "general", "route": "general", "route_method": "no_key"}

    # åˆå§‹åŒ– LLM (ä½¿ç”¨ Config ä¸­çš„é…ç½®)
    llm = ChatOpenAI(
        model=Config.MODEL_ROUTER,
        api_key=Config.SILICONFLOW_API_KEY,
        base_url=Config.BASE_URL,
        timeout=30,
        max_retries=0,
    )
    
    # ä½¿ç”¨ structured_output å¼ºåˆ¶è¾“å‡º JSON
    structured_llm = llm.with_structured_output(RouterOutput)
    
    # æ„é€  Prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
    ])
    
    # è°ƒç”¨é“¾
    chain = prompt | structured_llm
    
    # æ‰§è¡Œ
    try:
        # ä½¿ç”¨ safe_ainvoke_llm è¿›è¡Œå¼‚æ­¥é‡è¯•è°ƒç”¨
        result = await safe_ainvoke_llm(chain, {"messages": messages})
        logger.info(f"ğŸ‘‰ Router å†³å®šè·¯ç”±åˆ°: {result.next}")
        return {"next": result.next, "route": result.next, "route_method": "llm"}
    except Exception as e:
        logger.error(f"Router å‡ºé”™: {e}ï¼Œé»˜è®¤è·¯ç”±åˆ° general")
        return {"next": "general"}


async def general_node(state: AgentState):
    logger.info("ğŸ’¬ è¿›å…¥ General èŠ‚ç‚¹...")
    messages = state["messages"]
    last_user_text = ""
    for m in reversed(list(messages)):
        if isinstance(m, HumanMessage):
            last_user_text = (m.content or "").strip()
            break
    _ = last_user_text
    content = "\n".join(
        [
            "1) æˆ‘æ˜¯è°ï¼šæˆ‘æ˜¯ä¸€ä¸ªå¤šä»£ç† AI åŠ©æ‰‹ï¼Œä¸“æ³¨æ•°æ®åˆ†æä¸å…¬å¸æ”¿ç­–é—®ç­”ã€‚",
            "2) æˆ‘èƒ½åšæ•°æ®ï¼šå¯ä»¥ç®—æŒ‡æ ‡/æ‰¾å³°å€¼/ç”»å›¾ï¼›ä¾‹å¦‚â€œç”»ä¸€ä¸ªé”€å”®é¢è¶‹åŠ¿å›¾â€æˆ–â€œå“ªå¤©åˆ©æ¶¦æœ€é«˜ï¼Ÿâ€ã€‚",
            "3) æˆ‘èƒ½æŸ¥æ”¿ç­–ï¼šå¯ä»¥ä»å‘˜å·¥æ‰‹å†Œé‡Œæ£€ç´¢ç­”æ¡ˆï¼›ä¾‹å¦‚â€œå‡ºå·®æŠ¥é”€æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿâ€æˆ–â€œå¹´å‡æ€ä¹ˆè§„å®šï¼Ÿâ€ã€‚",
            "4) ä½ å¯ä»¥è¿™æ ·é—®ï¼šè¯´æ˜ä½ å…³å¿ƒçš„æŒ‡æ ‡/æ—¶é—´èŒƒå›´/åŸå¸‚æˆ–è§„åˆ™å…³é”®è¯ï¼Œæˆ‘ä¼šæ›´å¿«ç»™å‡ºç»“æœã€‚",
        ]
    )
    return {"messages": [AIMessage(content=content)]}

# 3. å®šä¹‰ Data Analyst (æ•°æ®åˆ†æå¸ˆ)
# èŒè´£ï¼šæ¥æ”¶æ•°æ®æŸ¥è¯¢ï¼Œç¼–å†™ Python ä»£ç ç»˜å›¾
async def analyst_node(state: AgentState):
    logger.info("ğŸ“Š è¿›å…¥ Analyst èŠ‚ç‚¹...")
    messages = state["messages"]

    df_path = Config.DATA_PATH
    if not os.path.exists(df_path):
        return {"messages": [AIMessage(content="é”™è¯¯ï¼šæ‰¾ä¸åˆ° sales_data.csv æ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")]}

    output_path = Config.OUTPUT_IMAGE_PATH
    python_repl = PythonAstREPLTool()

    last_user_text = ""
    for m in reversed(list(messages)):
        if isinstance(m, HumanMessage):
            last_user_text = (m.content or "").strip()
            break

    pending_code = state.get("pending_analyst_code")
    if pending_code:
        if _is_cancel_text(last_user_text):
            return {
                "pending_analyst_code": None,
                "messages": [AIMessage(content="å·²å–æ¶ˆæœ¬æ¬¡ä»£ç æ‰§è¡Œã€‚ä½ å¯ä»¥ç»§ç»­ææ–°çš„æ•°æ®åˆ†æé—®é¢˜ã€‚")],
            }
        if not _is_confirm_text(last_user_text):
            return {
                "messages": [
                    AIMessage(
                        content="æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡çš„å¾…æ‰§è¡Œä»£ç ã€‚å›å¤â€œç¡®è®¤â€æ‰§è¡Œï¼Œæˆ–å›å¤â€œå–æ¶ˆâ€æ”¾å¼ƒæ‰§è¡Œã€‚"
                    )
                ]
            }

        if _looks_dangerous(pending_code):
            return {
                "pending_analyst_code": None,
                "messages": [
                    AIMessage(
                        content="å®‰å…¨æ£€æŸ¥æœªé€šè¿‡ï¼šå¾…æ‰§è¡Œä»£ç åŒ…å«æ½œåœ¨å±é™©æ“ä½œï¼Œå·²æ‹’ç»æ‰§è¡Œã€‚è¯·æ¢ä¸€ç§é—®é¢˜æè¿°ã€‚"
                    )
                ],
            }

        bootstrap_code = f"""
import pandas as pd
import matplotlib.pyplot as plt
import os

plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

try:
    plt.rcParams['font.sans-serif'] = [
        'Noto Sans CJK SC',
        'Noto Sans CJK JP',
        'WenQuanYi Zen Hei',
        'WenQuanYi Micro Hei',        'SimHei',
        'Microsoft YaHei',
        'Arial Unicode MS',
    ]
except Exception:
    pass

df = pd.read_csv(r'{df_path}')

df['date'] = pd.to_datetime(df.get('æ—¥æœŸ', None), errors='coerce')
df['sales'] = df.get('é”€å”®é¢', None)
df['cost'] = df.get('æˆæœ¬', None)
df['profit'] = df.get('åˆ©æ¶¦', None)
df['product'] = df.get('äº§å“', None)

OUTPUT_PATH = r'{output_path}'

def save_figure(_plt=plt, _os=os, _path=OUTPUT_PATH):
    if _os.path.exists(_path):
        try:
            _os.remove(_path)
        except Exception:
            pass
    _plt.tight_layout()
    _plt.savefig(_path)
    _plt.close()
"""

        try:
            output = python_repl.run(f"{bootstrap_code}\n{pending_code}")
            return {
                "pending_analyst_code": None,
                "messages": [
                    AIMessage(
                        content="\n".join(
                            [
                                "ä»£ç å·²æ‰§è¡Œå®Œæˆã€‚",
                                f"å¦‚ç”Ÿæˆäº†å›¾è¡¨ï¼Œå°†ä¿å­˜ä¸ºï¼š{output_path}",
                                "",
                                "æ•°æ®è®¡ç®—ç»“æœï¼š",
                                str(output).strip() if str(output).strip() else "(æ— è¾“å‡º)",
                            ]
                        )
                    )
                ],
            }
        except Exception as e:
            return {
                "pending_analyst_code": None,
                "messages": [AIMessage(content=f"ä»£ç æ‰§è¡Œå‡ºé”™ï¼š{e}")],
            }

    deny_plot = any(
        x in last_user_text
        for x in (
            "ä¸è¦ç”»å›¾",
            "ä¸ç”»å›¾",
            "ä¸è¦ç»˜å›¾",
            "æ— éœ€ç”»å›¾",
            "åˆ«ç”»å›¾",
            "ä¸è¦ç”»",
            "åˆ«ç”»",
        )
    )
    plot_hint_patterns = [
        r"(ç”»|ç»˜|ç”Ÿæˆ|å±•ç¤º).*(å›¾|è¡¨|æ›²çº¿|åˆ†å¸ƒ|è¶‹åŠ¿)",
        r"(è¶‹åŠ¿|åˆ†å¸ƒ|å¯è§†åŒ–|plot|chart)",
    ]
    need_plot = (not deny_plot) and any(re.search(p, last_user_text) for p in plot_hint_patterns)

    system_prompt = "\n".join(
        [
            "ä½ æ˜¯ä¸€ä½ç²¾é€š Pandas å’Œ Matplotlib çš„æ•°æ®åˆ†æå¸ˆã€‚",
            f"æ•°æ®æº CSV è·¯å¾„ï¼š{df_path}ï¼ˆå·²åŠ è½½ä¸º dfï¼‰ã€‚",
            "df åŒæ—¶åŒ…å«ä¸­æ–‡åˆ—ï¼šæ—¥æœŸã€äº§å“ã€é”€å”®é¢ã€æˆæœ¬ã€åˆ©æ¶¦ï¼Œä»¥åŠè‹±æ–‡åˆ«ååˆ—ï¼šdateã€productã€salesã€costã€profitã€‚",
            "è¿è¡Œç¯å¢ƒå·²é¢„å…ˆ import pandas as pdã€matplotlib.pyplot as pltï¼Œå¹¶å·²æä¾› OUTPUT_PATH ä¸ save_figure()ï¼›ä¸è¦é‡æ–° importï¼Œä¹Ÿä¸è¦é‡æ–°å®šä¹‰ save_figure()ã€‚",
            "åªè¾“å‡ºå¯ç›´æ¥æ‰§è¡Œçš„ Python ä»£ç ï¼Œä¸è¦ Markdownï¼Œä¸è¦è§£é‡Šã€‚",
            "ä¸¥ç¦ç½‘ç»œè®¿é—®ã€ç³»ç»Ÿå‘½ä»¤ã€è¯»å†™é™¤ OUTPUT_PATH ä¹‹å¤–çš„æ–‡ä»¶ã€æˆ–ä»»ä½•ç ´åæ€§æ“ä½œã€‚",
        ]
        + (
            [
                f"æœ¬æ¬¡éœ€æ±‚éœ€è¦ç”»å›¾ï¼šå¿…é¡»ä¿å­˜åˆ° OUTPUT_PATHï¼ˆå˜é‡ï¼‰ï¼Œå¹¶åœ¨ä»£ç æœ«å°¾è°ƒç”¨ save_figure()ï¼Œç„¶å print(\"å›¾è¡¨å·²ç”Ÿæˆ\")ã€‚",
                "ä¸¥ç¦ä½¿ç”¨ plt.show()ã€‚",
            ]
            if need_plot
            else [
                "æœ¬æ¬¡éœ€æ±‚åªè¦ç»“è®ºï¼šä¸¥ç¦ç”»å›¾ï¼Œä¸è¦è°ƒç”¨ save_figure()ï¼Œåª print æœ€ç»ˆç»“è®ºï¼ˆåŒ…å«æ—¥æœŸä¸æ•°å€¼ï¼‰ã€‚"
            ]
        )
    )

    code = ""
    if not Config.SILICONFLOW_API_KEY:
        code = _fallback_analyst_code(last_user_text, need_plot)
    else:
        llm = ChatOpenAI(
            model=Config.MODEL_ANALYST,
            api_key=Config.SILICONFLOW_API_KEY,
            base_url=Config.BASE_URL,
            temperature=0,
            timeout=90,
            max_retries=0,
        )

        try:
            response = await safe_ainvoke_llm(
                llm, [HumanMessage(content=system_prompt), HumanMessage(content=last_user_text)]
            )
            code = _sanitize_generated_code(_extract_python_code(getattr(response, "content", "") or ""))
        except LLMAuthError:
            return {
                "messages": [
                    AIMessage(
                        content="LLM é‰´æƒå¤±è´¥ï¼šAPI Key æ— æ•ˆï¼Œæ— æ³•ä½¿ç”¨åœ¨çº¿æ¨¡å‹ç”Ÿæˆåˆ†æä»£ç ã€‚è¯·æ›´æ–° .env ä¸­çš„ SILICONFLOW_API_KEY å¹¶é‡å¯ api æœåŠ¡ã€‚"
                    )
                ]
            }
        except Exception as e:
            logger.error(f"Analyst ç”Ÿæˆä»£ç å¤±è´¥: {e}")
            code = _fallback_analyst_code(last_user_text, need_plot)
    if not code:
        return {"messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å¯æ‰§è¡Œä»£ç ã€‚è¯·æ¢ä¸€ç§é—®æ³•ã€‚")]}

    if _looks_dangerous(code):
        return {
            "messages": [
                AIMessage(content="å®‰å…¨æ£€æŸ¥æœªé€šè¿‡ï¼šç”Ÿæˆä»£ç åŒ…å«æ½œåœ¨å±é™©æ“ä½œã€‚è¯·æ¢ä¸€ç§é—®é¢˜æè¿°ã€‚")
            ]
        }

    if need_plot:
        if "save_figure()" not in code:
            code = f"{code.rstrip()}\n\nsave_figure()\nprint(\"å›¾è¡¨å·²ç”Ÿæˆ\")\n"
        if "plt.show(" in code.replace(" ", ""):
            code = code.replace("plt.show()", "")
        if "print(\"å›¾è¡¨å·²ç”Ÿæˆ\")" not in code and "print('å›¾è¡¨å·²ç”Ÿæˆ')" not in code:
            code = f"{code.rstrip()}\nprint(\"å›¾è¡¨å·²ç”Ÿæˆ\")\n"

    preview = "\n".join(
        [
            "æˆ‘å·²ç»ç”Ÿæˆäº†å°†è¦æ‰§è¡Œçš„åˆ†æä»£ç ã€‚ä¸ºä¿è¯å®‰å…¨ï¼Œéœ€è¦ä½ ç¡®è®¤åæ‰ä¼šè¿è¡Œã€‚",
            "å›å¤â€œç¡®è®¤â€æ‰§è¡Œï¼Œæˆ–å›å¤â€œå–æ¶ˆâ€æ”¾å¼ƒã€‚",
            "",
            "```python",
            code.strip(),
            "```",
        ]
    )
    return {"pending_analyst_code": code, "messages": [AIMessage(content=preview)]}

# 4. å®šä¹‰ Policy Expert (æ”¿ç­–ä¸“å®¶)
# èŒè´£ï¼šé€šè¿‡ RAG æ£€ç´¢çŸ¥è¯†åº“å›ç­”é—®é¢˜
async def expert_node(state: AgentState):
    logger.info("ğŸ“ è¿›å…¥ Expert èŠ‚ç‚¹...")
    messages = state["messages"]
    last_message = messages[-1]
    query = last_message.content
    
    # è°ƒç”¨ RAG å·¥å…· (å°è£…å¥½çš„å‡½æ•°)
    # RAG æ£€ç´¢æœ¬èº«å¯èƒ½æ˜¯åŒæ­¥çš„ (Chroma)ï¼Œå¦‚æœæ£€ç´¢å¾ˆæ…¢ï¼Œå¯ä»¥è€ƒè™‘æŠŠå®ƒä¹Ÿæ”¹æˆå¼‚æ­¥
    # ä½†ä¸ºäº†ä¸æ”¹åŠ¨å¤ªå¤šï¼Œè¿™é‡Œä¿ç•™åŒæ­¥è°ƒç”¨ï¼Œåæ­£æ£€ç´¢é€šå¸¸å¾ˆå¿«
    if not Config.SILICONFLOW_API_KEY:
        answer = _fallback_policy_search(query, Config.POLICY_PATH)
        return {"messages": [AIMessage(content=answer)]}

    try:
        context = search_company_policy(query)
        logger.info("âœ… Expert æ£€ç´¢å®Œæˆ")
        if (not context) or context.strip().lower().startswith("error:") or context.strip().startswith("No relevant information"):
            return {"messages": [AIMessage(content=context or "No relevant information found in the knowledge base.")]}

        llm = ChatOpenAI(
            model=Config.MODEL_EXPERT,
            api_key=Config.SILICONFLOW_API_KEY,
            base_url=Config.BASE_URL,
            temperature=0,
            timeout=60,
            max_retries=0,
        )
        system_prompt = "\n".join(
            [
                "ä½ æ˜¯å…¬å¸çš„æ”¿ç­–é—®ç­”åŠ©æ‰‹ã€‚",
                "ä½ å¿…é¡»åªæ ¹æ®ç»™å®šçš„ã€æ”¿ç­–ç‰‡æ®µã€‘å›ç­”ï¼Œä¸å…è®¸å¼•å…¥ç‰‡æ®µä¹‹å¤–çš„ä¿¡æ¯ã€‚",
                "å¦‚æœç‰‡æ®µä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¾“å‡ºï¼šNo relevant information found in the knowledge base.",
                "å›ç­”è¦ç®€æ´ï¼Œä¼˜å…ˆç”¨è¦ç‚¹åˆ—å‡ºäº¤é€š/ä½å®¿/é¤è¡¥ç­‰å…³é”®æ ‡å‡†ã€‚",
                "ä½ å¿…é¡»åœ¨æ¯ä¸ªè¦ç‚¹æœ«å°¾æ ‡æ³¨å¼•ç”¨æ¥æºç‰‡æ®µç¼–å·ï¼Œå¦‚â€œï¼ˆæ¥æºï¼šç‰‡æ®µ1ï¼‰â€ã€‚",
                "åªå…è®¸å¼•ç”¨ä¸é—®é¢˜å¼ºç›¸å…³çš„ç‰‡æ®µï¼›ä¸è¦ä½¿ç”¨æ— å…³ç‰‡æ®µå‡‘ç­”æ¡ˆã€‚",
            ]
        )
        user_prompt = "\n".join(
            [
                f"é—®é¢˜ï¼š{(query or '').strip()}",
                "",
                "ã€æ”¿ç­–ç‰‡æ®µã€‘",
                context.strip(),
            ]
        )
        response = await safe_ainvoke_llm(llm, [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)])
        answer = (getattr(response, "content", "") or "").strip() or context.strip()
        return {"messages": [AIMessage(content=answer)]}
    except Exception as e:
        logger.error(f"Expert å‡ºé”™: {e}")
        answer = _fallback_policy_search(query, Config.POLICY_PATH)
        return {"messages": [AIMessage(content=answer)]}

from langgraph.checkpoint.memory import MemorySaver

# 5. æ„å»ºå›¾ (Graph)
def create_graph(enable_interrupt: bool = True):
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("router", router_node)
    workflow.add_node("analyst", analyst_node)
    workflow.add_node("expert", expert_node)
    workflow.add_node("general", general_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("router")
    
    # æ·»åŠ æ¡ä»¶è¾¹ (Conditional Edges)
    # ä» router å‡ºå‘ï¼Œæ ¹æ® next å­—æ®µçš„å€¼å†³å®šå»å“ª
    workflow.add_conditional_edges(
        "router",
        lambda x: x["next"],
        {
            "analyst": "analyst",
            "expert": "expert",
            "general": "general",
        }
    )
    
    # ä» analyst å’Œ expert ç»“æŸ
    workflow.add_edge("analyst", END)
    workflow.add_edge("expert", END)
    workflow.add_edge("general", END)
    
    # åˆå§‹åŒ–è®°å¿†
    memory = MemorySaver()
    
    # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦å¼€å¯ä¸­æ–­
    if enable_interrupt:
        return workflow.compile(checkpointer=memory, interrupt_before=["analyst"])
    else:
        return workflow.compile(checkpointer=memory)

# 6. æµ‹è¯•è¿è¡Œ
# if __name__ == "__main__":
#     import asyncio
#     
#     async def main():
#         print("Initializing Graph...")
#         app = create_graph(enable_interrupt=False)
#         
#         # é…ç½®çº¿ç¨‹ID (ç”¨äºè®°å¿†)
#         config = {"configurable": {"thread_id": "1"}}
#         
#         # æµ‹è¯• 1: æ•°æ®é—®é¢˜
#         print("\n\nTest 1: Data Question")
#         inputs = {"messages": [HumanMessage(content="ç”»ä¸€ä¸ªé”€å”®é¢è¶‹åŠ¿å›¾")]}
#         
#         print("--- å¯åŠ¨ Graph ---")
#         # æ³¨æ„ï¼šç°åœ¨æ˜¯ ainvoke
#         result = await app.ainvoke(inputs, config=config)
#         print(result["messages"][-1].content)
# 
#     # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
#     asyncio.run(main())
