import streamlit as st
from openai import OpenAI
import os
import typing
import json
import statistics
import re

SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"
DEFAULT_CHAT_MODEL = "THUDM/glm-4-9b-chat"
AVAILABLE_MODELS = [
    "Qwen/Qwen2.5-7B-Instruct",
    "deepseek-ai/DeepSeek-V3",
    "deepseek-ai/DeepSeek-R1",
    "deepseek-ai/DeepSeek-V2.5",
    "THUDM/glm-4-9b-chat",
]


def load_env() -> None:
    try:
        from dotenv import load_dotenv

        load_dotenv()
    except Exception:
        return


def get_default_api_key() -> str:
    return os.getenv("SILICONFLOW_API_KEY", "")


def build_system_prompt() -> str:
    return (
        "ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 10 å¹´ç»éªŒçš„èµ„æ·±æŠ€æœ¯æ‹›è˜ä¸“å®¶ (HRBP)ã€‚\n"
        "ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©æ±‚èŒè€…ä¼˜åŒ–ç®€å†ï¼Œä½¿å…¶ç¬¦åˆç›®æ ‡å²—ä½çš„è¦æ±‚ã€‚\n\n"
        "è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n"
        "1. STAR æ³•åˆ™ï¼šå°†æ¨¡ç³Šçš„ç»å†æ”¹å†™ä¸º Situation(æƒ…å¢ƒ), Task(ä»»åŠ¡), Action(è¡ŒåŠ¨), Result(ç»“æœ)ã€‚\n"
        "2. æ•°å­—åŒ–æˆæœï¼šå°½å¯èƒ½ç”¨æ•°æ®é‡åŒ–æˆæœï¼ˆä¾‹å¦‚ï¼šæå‡äº† 50% æ•ˆç‡ï¼Œå¤„ç† 10w+ æ•°æ®ï¼‰ã€‚\n"
        "3. å…³é”®è¯ä¼˜åŒ–ï¼šæ ¹æ®ç›®æ ‡å²—ä½ï¼Œæ¤å…¥é«˜é¢‘æŠ€æœ¯å…³é”®è¯ï¼ˆå¦‚ Java, Spring Boot, MySQLï¼‰ã€‚\n"
        "4. ä¸“ä¸šæœ¯è¯­ï¼šæŠŠå£è¯­åŒ–è¡¨è¾¾æ”¹æˆä¸“ä¸šæœ¯è¯­ã€‚\n\n"
        "è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š\n"
        "- å…ˆç»™å‡º 3-5 æ¡ç®€çŸ­çš„ä¿®æ”¹å»ºè®®ã€‚\n"
        "- ç„¶åç»™å‡ºä¼˜åŒ–åçš„ç®€å†å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚\n"
    )


def build_user_prompt(target_job: str, raw_resume: str) -> str:
    return f"ç›®æ ‡å²—ä½ï¼š{target_job}\n\nåŸå§‹ç®€å†å†…å®¹ï¼š\n{raw_resume}\n"


def stream_chat_completion(
    api_key: str,
    model: str,
    messages: list[dict[str, str]],
) -> "typing.Iterator[str]":
    client = OpenAI(api_key=api_key, base_url=SILICONFLOW_BASE_URL)
    stream = client.chat.completions.create(
        model=model,
        messages=messages,
        stream=True,
    )

    full_response = ""
    for chunk in stream:
        delta = chunk.choices[0].delta
        if delta.content is not None:
            full_response += delta.content
            yield full_response


def chat_completion(api_key: str, model: str, messages: list[dict[str, str]]) -> str:
    client = OpenAI(api_key=api_key, base_url=SILICONFLOW_BASE_URL)
    resp = client.chat.completions.create(model=model, messages=messages, stream=False)
    return resp.choices[0].message.content or ""


def init_interview_state() -> None:
    if "interview" not in st.session_state:
        st.session_state.interview = {
            "active": False,
            "target_job": "",
            "questions": [],
            "current_index": 0,
            "turns": [],
        }


def reset_interview() -> None:
    st.session_state.interview = {
        "active": False,
        "target_job": "",
        "questions": [],
        "current_index": 0,
        "turns": [],
    }


def parse_questions_from_json(text: str) -> list[str]:
    text = text.strip()
    if not text:
        return []
    fenced = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", text, flags=re.IGNORECASE)
    if fenced:
        text = fenced.group(1).strip()
    json_candidate = None
    l = text.find("{")
    r = text.rfind("}")
    if 0 <= l < r:
        json_candidate = text[l : r + 1]
    try:
        data = json.loads(json_candidate or text)
        if isinstance(data, dict):
            data = data.get("questions", [])
        if isinstance(data, list):
            return [str(x).strip() for x in data if str(x).strip()]
    except Exception:
        pass
    questions: list[str] = []
    for ln in text.splitlines():
        ln = ln.strip()
        if not ln:
            continue
        ln = re.sub(r"^\s*(?:\d+[\.\)\ã€]|[-*â€¢])\s*", "", ln)
        ln = ln.strip()
        if ln:
            questions.append(ln)
    return questions


def extract_score_1_to_10(text: str) -> int | None:
    if not text:
        return None
    candidates: list[int] = []
    for m in re.finditer(r"è¯„åˆ†[^\d]{0,20}(\d{1,2})(?:\s*/\s*10)?", text):
        try:
            n = int(m.group(1))
        except Exception:
            continue
        if 1 <= n <= 10:
            candidates.append(n)
    if candidates:
        return candidates[0]
    m = re.search(r"(\d{1,2})\s*/\s*10", text)
    if m:
        try:
            n = int(m.group(1))
        except Exception:
            return None
        if 1 <= n <= 10:
            return n
    return None


def build_interview_question_generator_prompt(
    target_job: str,
    raw_resume: str,
    question_count: int,
    difficulty: str,
) -> list[dict[str, str]]:
    system = (
        "ä½ æ˜¯ä¸€ä½èµ„æ·± AI åº”ç”¨å·¥ç¨‹å¸ˆé¢è¯•å®˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºå€™é€‰äººçš„ç®€å†ï¼Œä¸ºç›®æ ‡å²—ä½ç”Ÿæˆé«˜è´¨é‡é¢è¯•é¢˜ã€‚\n"
        "è¦æ±‚ï¼šé¢˜ç›®è¦è¦†ç›– LLM è°ƒç”¨å·¥ç¨‹åŒ–ã€Prompt è®¾è®¡ã€RAGã€Embedding/å‘é‡åº“ã€è¯„æµ‹ä¸å¯è§‚æµ‹æ€§ã€æˆæœ¬ä¸å»¶è¿Ÿã€ä¸Šçº¿ä¸å®‰å…¨ã€‚\n"
        "é¢˜ç›®å¿…é¡»ç»“åˆå€™é€‰äººç®€å†ä¸­çš„é¡¹ç›®ç»†èŠ‚ï¼ˆè¦èƒ½è¿½é—®å‡ºå…·ä½“å®ç°ä¸å–èˆï¼‰ï¼Œä¸è¦å‡ºåç®—æ³•ç«èµ›é¢˜ã€‚\n"
        "è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™æ–‡å­—ã€‚\n"
        'JSON ç»“æ„ï¼š{"questions": ["é—®é¢˜1", "é—®é¢˜2", "..."]}\n'
    )
    user = (
        f"ç›®æ ‡å²—ä½ï¼š{target_job}\n"
        f"éš¾åº¦ï¼š{difficulty}\n"
        f"é¢˜ç›®æ•°é‡ï¼š{question_count}\n\n"
        f"å€™é€‰äººç®€å†ï¼š\n{raw_resume}\n"
    )
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]


def build_interview_evaluator_prompt(
    target_job: str,
    raw_resume: str,
    question: str,
    answer: str,
) -> list[dict[str, str]]:
    system = (
        "ä½ æ˜¯ä¸€ä½ä¸¥æ ¼ä½†å‹å¥½çš„æŠ€æœ¯é¢è¯•å®˜ã€‚\n"
        "ä½ ä¼šæ ¹æ®ç›®æ ‡å²—ä½ä¸å€™é€‰äººç®€å†ï¼Œè¯„ä»·å€™é€‰äººçš„å›ç­”å¹¶ç»™å‡ºå¯æ‰§è¡Œçš„æ”¹è¿›å»ºè®®ã€‚\n"
        "è¾“å‡ºå¿…é¡»ä½¿ç”¨ Markdownï¼Œå¹¶ä¸¥æ ¼æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š\n"
        "1) è¯„åˆ†ï¼ˆ1-10ï¼‰\n"
        "2) ä¼˜ç‚¹ï¼ˆè¦ç‚¹åˆ—è¡¨ï¼‰\n"
        "3) ä¸è¶³ï¼ˆè¦ç‚¹åˆ—è¡¨ï¼‰\n"
        "4) æ€ä¹ˆæ”¹ï¼ˆç»™å‡ºå¯ç›´æ¥èƒŒè¯µçš„è¡¨è¾¾/è¡¥å……ç‚¹ï¼‰\n"
        "5) å‚è€ƒç­”æ¡ˆï¼ˆç®€æ´ä½†ä¸“ä¸šï¼‰\n"
        "6) è¿½é—®ï¼ˆ2ä¸ªï¼‰\n"
        "å¦‚æœå›ç­”æ˜æ˜¾ç¼ºå¤±å…³é”®ä¿¡æ¯ï¼Œè¦æŒ‡å‡ºç¼ºå¤±ç‚¹ï¼Œå¹¶ç»™å‡ºè¡¥é½æ¨¡æ¿ã€‚\n"
    )
    user = (
        f"ç›®æ ‡å²—ä½ï¼š{target_job}\n\n"
        f"å€™é€‰äººç®€å†ï¼š\n{raw_resume}\n\n"
        f"é¢è¯•é¢˜ï¼š{question}\n\n"
        f"å€™é€‰äººå›ç­”ï¼š\n{answer}\n"
    )
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]


def build_interview_summary_prompt(target_job: str, turns: list[dict[str, str]]) -> list[dict[str, str]]:
    system = (
        "ä½ æ˜¯ä¸€ä½èµ„æ·± AI åº”ç”¨å·¥ç¨‹å¸ˆé¢è¯•å®˜ï¼Œè¯·åŸºäºæ•´åœºé¢è¯•çš„é—®ç­”è®°å½•ç»™å‡ºå¤ç›˜ã€‚\n"
        "è¯„ä»·ç»´åº¦å¿…é¡»è´´åˆ AI åº”ç”¨å·¥ç¨‹å¸ˆå²—ä½ï¼ˆä¸è¦æŒ‰ä¼ ç»Ÿ NLP/ç®—æ³•ç ”ç©¶å²—ç»™å»ºè®®ï¼‰ï¼š\n"
        "- LLM è°ƒç”¨å·¥ç¨‹åŒ–ï¼šmessages ç»“æ„ã€system/user/assistantã€streamã€è¶…æ—¶/é‡è¯•/é™æµã€æˆæœ¬æ§åˆ¶\n"
        "- Prompt è®¾è®¡ï¼šè§’è‰²/çº¦æŸ/è¾“å‡ºç»“æ„ã€é™ä½å¹»è§‰ã€å¯æ§æ€§\n"
        "- RAGï¼šåˆ‡åˆ†ç­–ç•¥ã€embedding é€‰å‹ã€Top-Kã€å¼•ç”¨ä¸å¯è¿½æº¯ã€è´¨é‡è¯„ä¼°ä¸æ’é”™é¡ºåº\n"
        "- äº¤ä»˜ä¸ä¸Šçº¿ï¼šæ—¥å¿—/ç›‘æ§ã€å¼‚å¸¸å¤„ç†ã€é…ç½®ç®¡ç†(.env)ã€å®‰å…¨ï¼ˆKey/PIIï¼‰ã€æµ‹è¯•\n"
        "\n"
        "è¾“å‡ºå¿…é¡»ä½¿ç”¨ Markdownï¼Œå¹¶ä¸¥æ ¼æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š\n"
        "1) æ€»ä½“è¯„ä»·ï¼ˆ3-5å¥ï¼Œå¿…é¡»ç»“åˆé—®ç­”ä¸­å‡ºç°çš„å…·ä½“è¡¨ç°ï¼‰\n"
        "2) ä¸‰ä¸ªæœ€è¯¥è¡¥çš„çŸ¥è¯†ç‚¹ï¼ˆæ¯æ¡ï¼šç¼ºå£è¡¨ç° â†’ åŸå›  â†’ 7å¤©æ€ä¹ˆè¡¥ï¼Œç»™åˆ°å…·ä½“ç»ƒä¹ ï¼‰\n"
        "3) ä¸‰ä¸ªé¡¹ç›®è¡¨è¾¾å¯ç›´æ¥å¥—ç”¨çš„å¥å¼ï¼ˆè¦èƒ½è½åˆ°å·¥ç¨‹ç»†èŠ‚ï¼šæŒ‡æ ‡/å–èˆ/æ’é”™ï¼‰\n"
        "4) ä¸‹æ¬¡é¢è¯•å‰ 30 åˆ†é’Ÿå†²åˆºæ¸…å•ï¼ˆåªåˆ—æœ€å…³é”® 6 æ¡ï¼‰\n"
        "5) é¢è¯•å®˜è§†è§’çš„è¿½é—®æ¸…å•ï¼ˆ5ä¸ªæœ€å¯èƒ½è¿½é—®ç‚¹ï¼ŒæŒ‰ä¼˜å…ˆçº§ï¼‰\n"
    )
    transcript = json.dumps(turns, ensure_ascii=False, indent=2)
    user = f"ç›®æ ‡å²—ä½ï¼š{target_job}\n\né—®ç­”è®°å½•(JSON)ï¼š\n{transcript}\n"
    return [{"role": "system", "content": system}, {"role": "user", "content": user}]


def render_page() -> None:
    st.set_page_config(page_title="AI ç®€å†ä¼˜åŒ–ä¸“å®¶", page_icon="ğŸ‘”", layout="wide")
    st.title("ğŸ‘” ç®€å†ä¼˜åŒ– + é¢è¯•æ¨¡æ‹Ÿ")
    st.markdown("å…ˆæŠŠç®€å†æ”¹åˆ° HR çˆ±çœ‹ï¼Œå†ç”¨é¢è¯•å®˜æ¨¡å¼æŠŠå›ç­”ç»ƒåˆ°ç¨³å®šã€‚")
    init_interview_state()

    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        api_key = st.text_input("API Key", value=get_default_api_key(), type="password")
        model_choice = st.selectbox(
            "æ¨¡å‹",
            AVAILABLE_MODELS,
            index=0,
        )
        st.divider()
        st.write(f"Base URLï¼š{SILICONFLOW_BASE_URL}")

    tab_resume, tab_interview = st.tabs(["ç®€å†ä¼˜åŒ–", "é¢è¯•æ¨¡æ‹Ÿ"])

    with tab_resume:
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“ è¾“å…¥")
            target_job = st.text_input("ç›®æ ‡å²—ä½", placeholder="ä¾‹å¦‚ï¼šJava åç«¯å®ä¹ ç”Ÿ / å¤§æ•°æ®å¼€å‘", key="resume_target_job")
            raw_resume = st.text_area(
                "åŸå§‹ç®€å†/ç»å†æè¿°",
                height=420,
                placeholder="ä¾‹å¦‚ï¼š\næˆ‘åœ¨å¤§å­¦åšäº†ä¸ªå›¾ä¹¦ç®¡ç†ç³»ç»Ÿï¼Œç”¨äº†Java...\næˆ‘è¿˜å‚åŠ è¿‡æ•°å­¦å»ºæ¨¡æ¯”èµ›...\næˆ‘æ˜¯è®¡ç®—æœºåä¼šä¼šé•¿...",
                key="resume_raw_resume",
            )
            submit_btn = st.button("å¼€å§‹ä¼˜åŒ–", type="primary", use_container_width=True, key="resume_submit")
        with col2:
            st.subheader("âœ¨ è¾“å‡º")
            result_container = st.empty()

        if submit_btn:
            if not api_key:
                st.error("è¯·å…ˆé…ç½® API Keyï¼ˆå·²æ”¯æŒä» .env è‡ªåŠ¨è¯»å–ï¼‰ã€‚")
            elif not target_job.strip() or not raw_resume.strip():
                st.error("è¯·å¡«å†™ç›®æ ‡å²—ä½ä¸åŸå§‹ç®€å†å†…å®¹ã€‚")
            else:
                system_prompt = build_system_prompt()
                user_prompt = build_user_prompt(target_job=target_job, raw_resume=raw_resume)
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ]
                try:
                    result_container.markdown("ç”Ÿæˆä¸­â€¦")
                    last = ""
                    for partial in stream_chat_completion(api_key=api_key, model=model_choice, messages=messages):
                        last = partial
                        result_container.markdown(partial + "â–Œ")
                    result_container.markdown(last)
                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")

    with tab_interview:
        st.subheader("ğŸ™ï¸ é¢è¯•å®˜æ¨¡å¼ï¼ˆæŒ‰é¢˜ç»ƒå›ç­”ï¼‰")
        col_cfg, col_run = st.columns([1, 1])

        with col_cfg:
            target_job_i = st.text_input("ç›®æ ‡å²—ä½", placeholder="ä¾‹å¦‚ï¼šJava åç«¯å®ä¹ ç”Ÿ", key="interview_target_job")
            raw_resume_i = st.text_area(
                "ç®€å†/ç»å†ï¼ˆç”¨äºå®šåˆ¶é¢˜ç›®ï¼‰",
                height=260,
                placeholder="æŠŠä½ ç®€å†çš„é¡¹ç›®ç»å†ç²˜è´´åˆ°è¿™é‡Œï¼Œé¢˜ç›®ä¼šæ›´è´´åˆä½ ã€‚",
                key="interview_raw_resume",
            )
            question_count = st.slider("é¢˜ç›®æ•°é‡", min_value=5, max_value=15, value=8, step=1)
            difficulty = st.selectbox("éš¾åº¦", ["åŸºç¡€", "è¿›é˜¶", "åéš¾"], index=1)

        with col_run:
            start_btn = st.button("å¼€å§‹ç”Ÿæˆé¢˜ç›®", type="primary", use_container_width=True)
            reset_btn = st.button("é‡ç½®æœ¬æ¬¡é¢è¯•", use_container_width=True)

        if reset_btn:
            reset_interview()

        if start_btn:
            if not api_key:
                st.error("è¯·å…ˆé…ç½® API Keyï¼ˆå·²æ”¯æŒä» .env è‡ªåŠ¨è¯»å–ï¼‰ã€‚")
            elif not target_job_i.strip() or not raw_resume_i.strip():
                st.error("è¯·å¡«å†™ç›®æ ‡å²—ä½ä¸ç®€å†/ç»å†ã€‚")
            else:
                try:
                    prompt_msgs = build_interview_question_generator_prompt(
                        target_job=target_job_i,
                        raw_resume=raw_resume_i,
                        question_count=question_count,
                        difficulty=difficulty,
                    )
                    raw = chat_completion(api_key=api_key, model=model_choice, messages=prompt_msgs)
                    questions = parse_questions_from_json(raw)
                    questions = questions[:question_count]
                    if not questions:
                        st.error("é¢˜ç›®ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
                        with st.expander("ç”ŸæˆåŸæ–‡ï¼ˆç”¨äºæ’é”™ï¼‰"):
                            st.code(raw)
                    else:
                        st.session_state.interview = {
                            "active": True,
                            "target_job": target_job_i,
                            "raw_resume": raw_resume_i,
                            "questions": questions,
                            "current_index": 0,
                            "turns": [],
                        }
                        st.success(f"å·²ç”Ÿæˆ {len(questions)} é“é¢˜ï¼Œå¼€å§‹ç¬¬ 1 é¢˜ã€‚")
                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")

        iv = st.session_state.interview
        if iv.get("active"):
            idx = int(iv.get("current_index", 0))
            questions = iv.get("questions", [])
            if 0 <= idx < len(questions):
                st.markdown(f"### ç¬¬ {idx + 1}/{len(questions)} é¢˜")
                st.write(questions[idx])

                answer = st.text_area("ä½ çš„å›ç­”", height=180, key=f"answer_{idx}")
                col_a, col_b = st.columns([1, 1])
                submit_answer = col_a.button("æäº¤å›ç­”å¹¶ç‚¹è¯„", type="primary", use_container_width=True, key=f"submit_{idx}")
                skip_question = col_b.button("è·³è¿‡æœ¬é¢˜", use_container_width=True, key=f"skip_{idx}")

                if skip_question:
                    iv["turns"].append(
                        {"question": questions[idx], "answer": "", "feedback": "å·²è·³è¿‡"}
                    )
                    iv["current_index"] = idx + 1
                    st.rerun()

                if submit_answer:
                    if not answer.strip():
                        st.error("å…ˆå†™ç‚¹å›ç­”å†æäº¤ã€‚")
                    else:
                        try:
                            msgs = build_interview_evaluator_prompt(
                                target_job=iv["target_job"],
                                raw_resume=iv["raw_resume"],
                                question=questions[idx],
                                answer=answer,
                            )
                            st.markdown("ç‚¹è¯„ä¸­â€¦")
                            feedback = chat_completion(api_key=api_key, model=model_choice, messages=msgs)
                            score = extract_score_1_to_10(feedback)
                            iv["turns"].append(
                                {"question": questions[idx], "answer": answer, "feedback": feedback, "score": score}
                            )
                            st.markdown(feedback)
                            iv["current_index"] = idx + 1
                            st.rerun()
                        except Exception as e:
                            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
            else:
                st.success("æœ¬æ¬¡é¢è¯•é¢˜å·²å®Œæˆã€‚")
                turns = iv.get("turns", [])
                scores = [t.get("score") for t in turns if isinstance(t.get("score"), int)]
                if scores:
                    st.write(f"å¹³å‡è¯„åˆ†ï¼š{statistics.mean(scores):.1f}/10")
                if st.button("ç”Ÿæˆé¢è¯•å¤ç›˜", type="primary", use_container_width=True):
                    try:
                        msgs = build_interview_summary_prompt(target_job=iv["target_job"], turns=turns)
                        summary = chat_completion(api_key=api_key, model=model_choice, messages=msgs)
                        st.markdown(summary)
                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")


load_env()
render_page()
