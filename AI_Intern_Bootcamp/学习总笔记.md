# AI 实战项目学习总笔记（Day 1-5：一个项目学会）

这份文档是你本次项目的唯一学习入口：**不分散到多个 MD 文件**，所有要学的点、代码位置、练习与完成标准都集中在这里。  
源码对照：
- 简历优化 + 面试模拟：[quick_start_ai.py](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py)
- 企业知识库（RAG）：[rag_app.py](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py)
- 链式生成（大纲→正文）：[chain_writer.py](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py)

---

## 先记住：你要学的“重点是什么”（别学散）

你这条主线的目标是 **纯 AI 应用工程师**，重点不是传统 NLP 算法细节，而是把模型做成可交付系统：
- 会用 OpenAI 兼容接口：messages、stream、base_url、超时/重试、错误处理
- 会写 Prompt：角色/约束/输出结构，让输出可控、可复用、可评估
- 会做 RAG：切分、embedding、向量库、Top-K、引用、答不准怎么排错
- 会做“链式流程”：多次模型调用串联（先产出中间物，再继续下一步）
- 会做工程化：.env、状态管理、端口/进程、最小闭环与可复盘

## 0. 项目怎么跑（你必须能独立运行）

在 `AI_Workspace/AI_Intern_Bootcamp` 目录下执行：

**简历优化 + 面试模拟**
```powershell
streamlit run quick_start_ai.py
```

**企业知识库（RAG）**
```powershell
streamlit run rag_app.py
```

**链式生成（Day 4-5）**
```powershell
streamlit run chain_writer.py
```

**记忆聊天（Day 6）**
```powershell
streamlit run memory_chatbot.py
```

### 常见问题：为什么我一刷新就“服务不可用”？

Streamlit 的网页是靠终端里正在运行的进程提供服务的：进程停了/端口被占用/热更新时报错，浏览器就会提示“无法访问/服务不可用”。  
稳定做法：用一个终端专门跑 `streamlit run ...`，不要在同一个终端再执行其他命令。

---

## 1. 配置怎么做（你必须养成职业习惯）

### 1.1 用 `.env` 保存 Key（不要每次手输、不要写进代码）

文件路径：[.env](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/.env)

内容示例：
```bash
SILICONFLOW_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
```

代码里会自动读取：
- 简历/面试：[load_env](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L20) + [get_default_api_key](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L29)
- RAG：[load_env](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py#L18) + [get_default_api_key](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py#L27)
- 链式生成：[load_env](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py#L9) + [get_api_key](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py#L18)

### 1.2 Streamlit 的底层事实（必须理解）

**你每点一次按钮 / 输入一次内容，Streamlit 会把整个 Python 文件从上到下重新执行一遍。**  
因此你的排错顺序永远是：
- 变量丢了 → 需要 `st.session_state`
- 点了按钮没反应 → 走没走到判断分支（`return`/`if not ...`）
- 配置每次都要输 → `.env` / `session_state` 记住

---

## Day 1：你真正学到的是「怎么调用模型」

### 你必须掌握什么（3件事）
- **messages 协议**：`system/user/assistant` 三种角色 + `content`
- **Base URL**：同一套代码切换不同厂商，本质是换“服务器地址”
- **stream**：流式输出让体验更像真实产品

### 你需要背下来的固定套路（可复用）
```python
client.chat.completions.create(
    model="...",
    messages=[
        {"role": "system", "content": "..."},
        {"role": "user", "content": "..."},
    ],
    stream=True,
)
```

### 在你的项目代码里在哪里
- 固定 Base URL（硅基）：[quick_start_ai.py](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L7)
- 真正的模型调用（messages + stream）：[stream_chat_completion](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L52)

### Day 1 自测（你必须能做出来）
- 把模型换成另一个（不改其它逻辑）也能跑通一次调用
- 把 `stream=True` 改成 `stream=False`（你需要自己写一次性显示逻辑），理解体验差异

---

## Day 2：你真正学到的是「Prompt Engineering」

### 你必须掌握什么（3件事）
- **角色（Role）**：让模型“以谁的身份”工作（HR/面试官/导师）
- **规则（Constraint）**：必须遵守什么（STAR、数据化、不要编造）
- **输出结构（Format）**：必须输出 Markdown/JSON，否则结果不可控

### 在你的项目代码里在哪里
- 业务规则（System Prompt）：[build_system_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L40)
- 把输入变成任务（User Prompt）：[build_user_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L65)
- 面试题解析（解决“题目空白”）：[parse_questions_from_json](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L99)

### Day 2 自测（你必须能做出来）
- 把 HR 改成“严格面试官”，让它输出更尖锐的修改建议
- 把输出改成 JSON：必须包含 `suggestions` 与 `resume_markdown`

---

## Day 3：你真正学到的是「RAG（让 AI 读文档）」

RAG = **先找资料（检索），再让模型总结**。  
你今天能答对“住宿标准”，不是模型记住了员工手册，而是它先检索到了段落，然后把段落塞进 prompt。

### 你必须掌握什么（5件事）
- **切块（chunk）**：长文档必须切成小块
- **Embedding**：文字 → 向量（数字）
- **向量库**：存每个块的向量（这里用 Chroma）
- **Retriever**：负责从向量库取最相关块（Top-K）
- **把 context 塞回 prompt**：这是 RAG 的灵魂

### 在你的项目代码里在哪里
- 固定配置（Base URL/文档/模型）：[rag_app.py](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py#L12-L16)
- 文档加载→切分→向量化→入库→检索器： [build_retriever](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py#L59)
- Prompt 模板： [build_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/rag_app.py#L48)

### Day 3 自测（你必须能做出来）
- 把 [company_policy.txt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/company_policy.txt) 换成你自己的 `notes.txt`（先 txt）
- 至少问 5 个问题：答案必须能在文档里找到
- 通过调 `chunk_size` 改善答不准的问题（理解“检索质量”才是关键）

---

## Day 4（方向 B）：简历 + 面试官模拟（把“会改简历”变成“能上岸”）

你现在的简历应用新增了一个 **“面试模拟”** 标签页。它实现了一个最小闭环：
1) 用你的简历 + 岗位生成题目  
2) 你逐题回答  
3) AI 按固定结构给点评 + 参考答案 + 追问  
4) 面试结束输出复盘

### 你必须掌握什么（4件事）
- **同一套模型调用**可以做不同任务：换 Prompt 就像换应用
- **结构化输出**：强制按模板输出（评分/优点/不足/怎么改/参考答案/追问）
- **状态管理**：面试是“多轮流程”，要靠 `st.session_state` 记住进度
- **最小闭环思维**：能跑通“生成题→答题→点评→复盘”，比堆功能更重要

### 在你的项目代码里在哪里
- 面试状态初始化/重置：见 [init_interview_state](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L74) / [reset_interview](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L88)
- 生成题目（JSON 输出）：[build_interview_question_generator_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L155)
- 点评模板（固定结构）：[build_interview_evaluator_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L177)
- 复盘模板（已按“纯 AI 应用工程师”调整维度）：[build_interview_summary_prompt](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/quick_start_ai.py#L204)

### Day 4 自测（你必须能做出来）
- 把“难度”从基础改成偏难，观察题目变化（理解 prompt 条件控制）
- 让点评输出改成“更严格/更友好”两种版本（只改 Prompt，不动模型调用）
- 用同一套机制做一个新模式：“项目深挖模式”（只问你简历里某个项目 10 个追问）

---

## Day 5：你真正学到的是「链式调用（Chain）」

你做任何更复杂的 AI 应用，本质都是“把多次调用串起来”。链式调用的核心不是“多调用一次”，而是：
- 明确每一步的输入/输出（中间产物必须可读、可复盘）
- 每一步都写清规则（输出结构化，下一步才能稳定消费）
- 失败可排错（能看到每一步产物，定位是哪一步出问题）

### 你必须掌握什么（3件事）
- **中间产物**：先产出大纲/计划/检索结果，再进入下一步
- **约束输出**：要求大纲必须 Markdown、有层级、有要点
- **把第 1 步输出喂给第 2 步**：这是“链”的本质

### 在你的项目代码里在哪里
- 第一步生成大纲：[make_outline](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py#L27)
- 第二步基于大纲写正文：[make_article](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py#L42)
- 串联流程（先大纲→再正文）：[render](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/chain_writer.py#L57)

### Day 5 自测（你必须能做出来）
- 把“大纲输出规则”改得更严格：必须包含 5 个二级标题、每个标题 3 个要点
- 把“正文规则”改成：每个二级标题结尾必须给一个小结
- 能解释清楚：为什么链式调用比一次性让模型写全文更稳定（因为中间产物可控）

---

## Day 6：你真正学到的是「记忆（Memory）」

你要做的不是“让 AI 永远记住所有对话”，而是学会工程上最常用的两种记忆：
- **缓冲记忆（Buffer Memory）**：保留最近 N 轮对话，让模型保持短期上下文
- **总结式记忆（Summary Memory）**：当对话变长，把旧对话压缩成要点摘要，既省 token 又更稳定

这就是为什么 Day 6 对 **纯 AI 应用工程师** 很重要：你能解释“为什么要记忆、怎么控成本、怎么保证稳定性”。

### 你必须掌握什么（4件事）
- **记忆放在哪里**：`st.session_state` 保存对话缓冲区与摘要
- **什么时候触发总结**：对话超过阈值就压缩（否则越聊越贵、越聊越不稳定）
- **总结的目标**：只保留“未来有用信息”（目标/偏好/约束/已确认事实）
- **模型提示怎么用记忆**：系统提示里先给摘要，再给最近对话

### 在你的项目代码里在哪里
- 记忆状态初始化：[init_state](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L21)
- 触发总结条件（阈值）：[should_summarize](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L39) + [MAX_BUFFER_MESSAGES](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L8)
- 总结式记忆生成：[summarize_memory](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L43)
- 把“摘要 + 最近对话”喂给模型：[build_messages_for_model](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L66)
- UI 入口（对话/清空）：[render](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L84)

### Day 6 自测（你必须能做出来）
- 连续聊 15 轮，观察侧边栏“记忆摘要”从空变成要点（理解压缩机制）
- 把 `MAX_BUFFER_MESSAGES` 改小/改大，观察总结触发频率与回答稳定性的变化
- 让摘要格式更结构化：改成固定字段（目标/偏好/约束/已确认事实），并验证回答更可控

---

## Day 7：你真正学到的是「把记忆做成可交付（持久化 + 可复盘）」

Day 6 解决的是“当前会话内记忆”。但真正的产品要解决的是：**服务重启/刷新后记忆还在**。  
这就是 Day 7 的目标：把记忆保存到本地文件，让它成为可交付能力。

### 你必须掌握什么（3件事）
- **持久化存储**：把 `chat_messages` 和 `memory_summary` 存到本地 JSON 文件
- **启动时加载**：应用启动先读取文件，恢复记忆与最近对话
- **状态与文件一致性**：每次新增一轮对话后都写回文件，清空时也要清空文件

### 在你的项目代码里在哪里
- 记忆文件路径（.local_state）：[get_state_file_path](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L24)
- 启动加载记忆：[load_persisted_state](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L31) + [init_state](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L55)
- 每轮对话后保存：[save_persisted_state](file:///c:/Users/czy/PycharmProjects/doubanfx/AI_Workspace/AI_Intern_Bootcamp/memory_chatbot.py#L43)

### Day 7 自测（你必须能做出来）
- 跟机器人聊 5 轮 → 关掉服务 → 重新启动 → 记忆摘要与最近对话仍然存在
- 点击“清空记忆与聊天记录” → 重启服务 → 仍然为空（文件同步清空）

---

## 面试话术（你背这几句就够用了）

- Day 1（调用能力）：我熟悉 OpenAI 兼容接口，能通过 base_url 切换不同厂商模型，并实现流式输出交互。
- Day 2（Prompt 能力）：我能用角色、约束、输出格式编写结构化 Prompt，让同一个模型完成不同业务任务，并保持输出稳定。
- Day 3（RAG 能力）：我做过基于 LangChain 的 RAG 知识库问答：文档切分、向量化存储（Chroma）、相似度检索再生成回答，降低幻觉并适配中文场景（bge-m3 embedding）。
- Day 4（面试模拟）：我做过面试模拟闭环：基于简历生成定制题目，多轮点评与复盘，使用 session_state 管理流程，输出结构化反馈便于迭代提升。
- Day 6（记忆）：我实现过“缓冲记忆 + 总结式记忆”的对话系统：对话超过阈值自动压缩成摘要，既降低 token 成本又提升长对话稳定性，并用系统提示优先注入关键记忆。
